---
layout: home
excerpt: "You Zhang's Homepage"
---

[//]: # (This project is a slight customization based off of some great work by [NC State University Libraries](https://www.lib.ncsu.edu/. )

I am a Seniro Researcher on Spatial Audio and Multimodal AI at [Dolby Laboratories](https://www.dolby.com/) and a PhD candidate at the [Audio Information Research Lab](https://labsites.rochester.edu/air/), University of Rochester, NY, USA. I am fortunate to work with [Prof. Zhiyao Duan](https://hajim.rochester.edu/ece/sites/zduan/) during my PhD. Take a look at [my CV](./You_Neil_Zhang_CV_2025_Jul.pdf).

My research focuses on applied machine learning, particularly in speech and audio processing.
This includes topics such as **spatial audio, audio deepfake detection, and audio-visual rendering and analysis**. My research contributions have been showcased at prestigious venues such as ICASSP, WASPAA, Interspeech, SPL, TMM. I received recognition through the Rising Star Program in Signal Processing at ICASSP 2023, the Graduate Research Fellowship Program from National Institute of Justice, and IEEE Signal Processing Society Scholarship.

In my spare time, I am fond of paddle boarding, traveling, and movies.

<!-- If you are interested in my research or would like to collaborate with me, you are welcome to email me. -->

<!-- You (Neil) Zhang is a PhD candidate in the Department of Electrical and Computer Engineering at University of Rochester. His research centers on applied machine learning with a specialization in speech and audio processing, including areas such as audio deepfake detection, spatial audio, and audio-visual analysis. Neil's work has been showcased at prestigious venues such as ICASSP, WASPAA, Interspeech, SPL, and TMM. He has also gained industrial research experience through internships at Bytedance, Tencent, Microsoft, and Meta. His achievements have been recognized by the Rising Star Program in Signal Processing at ICASSP 2023 and the NIJ Graduate Research Fellowship Program. -->

<span style="color:red">I am actively seeking postdoc and faculty positions in academia as well as research scientist roles in industrial labs. Please feel free to reach out if you have opportunities or would like to connect!</span>

[Research Statement](./resources/You_Neil_Zhang_research_statement.pdf) \| [Teaching Statement](./resources/You_Neil_Zhang_teaching_statement.pdf) \| [Diversity Statement](./resources/You_Neil_Zhang_diversity_statement.pdf)


### News
[2025/07] One paper accepted by [IEEE WASPAA 2025](https://waspaa.com/)!

[2025/06] I joied Dolby Lab at Atlanta as a Senior Researcher!

[2025/06] One paper accepted by [Interpseech 2025](https://interspeech2025.org/) and one paper accepted by [IEEE ICIP 2025](https://2025.ieeeicip.org/)!

[2025/04] I received [Open Scholarship Awards from OSC Rochester](https://opensci.lib.rochester.edu/open-scholarship-awards) for commitment to openness in academic research! 

[2024/12] We are organizing the [SVDD special session](https://svddchallenge.org/challenges/special_session_ieee_slt.html) @ IEEE SLT 2024!

[2024/11] I was awarded the [**IEEE SPS Scholarship**](https://www.credential.net/2d530448-6949-4ea9-b8d9-c2ea5d731cd0)! Thank you, IEEE Signal Processing Society!

[2024/09] Our new WildSVDD challenge is held successfully at [MIREX @ ISMIR 2024](https://www.music-ir.org/mirex/wiki/2024:Singing_Voice_Deepfake_Detection)! 

[2024/08] Our SVDD challenge overview paper is accepted by [IEEE SLT 2024](https://2024.ieeeslt.org/)! 

[2024/08] One paper accepted by [MMSP 2024](https://attend.ieee.org/mmsp-2024/). Congrats, Kyungbok! 

[2024/07] We presented our tutorial on ["Multimedia Deepfake Detection"](https://github.com/yzyouzhang/Awesome-Multimedia-Deepfake-Detection) at [ICME 2024](https://2024.ieeeicme.org/).

[2024/05] I joined Meta Reality Labs Research Audio as a Research Scientist Intern, working with Dr. [Ishwarya Ananthabhotla](https://www.ishwarya.me/).

[2024/04] I gave a 1-hour tutorial on "Personalizing Spatial Audio: Machine Learning for Personalized Head-Related Transfer Functions (HRTFs) Modeling in Gaming" at [2024 AES International Conference on Audio for Games](https://aes2.org/events-calendar/2024-aes-6th-international-conference-on-audio-for-games/). [[Slides](./resources/Personalizing_Spatial_Audio_Machine_Learning_for_Personalized_Head-Related_Transfer_Functions_(HRTFs)_Modeling_in_Gaming.pdf)]

[2024/04] I attended [NEMISIG 2024](https://2024.nemisig.net/), [NYC Computer Vision Day 2024](https://cs.nyu.edu/~fouhey/NYCVision2024/) and [ICASSP 2024](https://2024.ieeeicassp.org/).

[2024/04] Exciting milestone achieved! I have successfully passed my PhD proposal/qualifying exam on "Generalizing Audio Deepfake Detection". Looking forward to embarking on this fruitful road!

[2024/04] Our inaugural Singing Voice Deepfake Detection (SVDD) 2024 Challenge proposal has been accepted by IEEE Spoken Language Technology Workshop (SLT) 2024! Check out the challenge website [here](https://challenge.singfake.org/)! Registration deadline: June 8th.

[2024/03] I gave a talk at [GenAI Spring School](https://aihouse.org.ua/en/event/generative-ai-spring-school/) and [AI Bootcamp](https://www.meetup.com/5b95b105-bc24-49fb-b4f8-9ddfcb5db0ff/events/299933650/) on "Audio Deepfake Detection".

[2024/02] I was delighted to share insights on detecting audio deepfakes in a recent piece by [NBC News](https://www.nbcnews.com/tech/misinformation/ai-generated-audio-detect-tool-model-rcna136634).

[2023/12] I gave a talk at Nanjing University on "Improving Generalization Ability for Audio Deepfake Detection". [[Slides](./resources/Improving_Generalization_Ability_for_Audio_Deepfake_Detection_20231228_Nanjing_University.pdf)]

[2023/12] Two papers accepted by [ICASSP 2024](2024.ieeeicassp.org). ([SingFake]() and [Speech Emotion AV Learning](https://arxiv.org/abs/2311.14816)) Congrats, Yongyi and Enting! 

[2023/11] I sat down with Berkeley Brean at News10NBC to talk about audio deepfake detection. [[WHEC-TV Link](https://www.whec.com/investigations/news10nbc-investigates-heres-what-happened-when-we-did-a-deep-fake-on-berkeley-breans-voice/)] [[Tweet1](https://twitter.com/whec_bbrean/status/1730299267544236042)] [[Tweet2](https://twitter.com/whec_bbrean/status/1730313761574055959)] [[Hajim Highlights](https://www.rochester.edu/communications/newsletters/hajim/hajim-highlights-1204/)]

[2023/11] I attended [WASPAA](https://waspaa.com/), [SANE](https://www.saneworkshop.org/sane2023/), [NRT Annual Meeting](https://nrt.asu.edu/nsf-annual-meeting/), and [BASH](https://binaural.and.spatialhearing.org/) to present our work on personalized spatial audio. Busy but exciting two weeks!

[2023/10] Received [**National Institute of Justice's (NIJ) Graduate Research Fellowship Award**](https://nij.ojp.gov/funding/fellowships/graduate-research-fellowship-program). [[NIJ Description](https://nij.ojp.gov/funding/awards/15pnij-23-gg-01933-ress)] [[UR News Center](https://www.rochester.edu/newscenter/audio-deepfake-detective-developing-new-sleuthing-techniques-573482/)] [[Hajim Highlights](https://www.rochester.edu/communications/newsletters/hajim/hajim-highlights-1113/)]

[2023/07] [One paper](https://ieeexplore.ieee.org/document/10248178) accepted by [WASPAA 2023](https://waspaa.com/). Congrats, Yutong!

[2023/06] Our paper "[HRTF Field](https://ieeexplore.ieee.org/document/10095801)" was recognized as one of the [top 3% of all papers accepted at ICASSP 2023](https://2023.ieeeicassp.org/top-3-percent-paper-recognitions/). [[Hajim Highlights](https://www.rochester.edu/communications/newsletters/hajim/620222/)]

[2023/05] Recognized as one of the [ICASSP Rising Stars in Signal Processing](https://2023.ieeeicassp.org/rising-stars-workshop). [[poster](./resources/ICASSP2023_Rising_Star_Neil_final.pdf)]


<!-- <details>


<summary>More archived news.</summary> -->


[2023/05] [One paper](https://www.isca-speech.org/archive/interspeech_2023/zang23_interspeech.html) accepted by [Interspeech 2023](https://www.interspeech2023.org/). Congrats, Yongyi!


[2023/02] Two papers accepted by [ICASSP 2023](https://2023.ieeeicassp.org/). ([HRTF Field](https://arxiv.org/abs/2210.15196) and [SAMO](https://arxiv.org/abs/2211.02718)) Congrats, Siwen!


[2023/02] Delivered a talk at [ISCA SIG-SPSC webinar](https://www.spsc-sig.org/webinar), titled "Generalizing Voice Presentation Attack Detection to Unseen Synthetic Attacks". [[slides](https://www.spsc-sig.org/sites/default/files/2023-02/SPSC-Webinar-GeneralizingVoicePresentationAttackDetection-20230206.pdf)]


<!-- </details> -->


### Selected Publications
(For full list, see [Publications](https://yzyouzhang.com/research/))

[3] You Zhang, Yongyi Zang, Jiatong Shi, Ryuichi Yamamoto, Tomoki Toda, and Zhiyao Duan,
**SVDD 2024: The Inaugural Singing Voice Deepfake Detection Challenge**, in *Proc. IEEE Spoken Language Technology Workshop (SLT)*, 2024. 
[[arXiv](https://arxiv.org/abs/2408.16132)] [[code](https://github.com/SVDDChallenge)] [[illuminate](https://illuminate.google.com/library?play=LGAsgb_o9oZp)] [[webpage](https://main.singfake.org/)] 

[2] You Zhang, Yuxiang Wang, and Zhiyao Duan,
**HRTF Field: Unifying Measured HRTF Magnitude Representation with Neural Fields**, in *Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*, 2023. 
[[DOI](https://ieeexplore.ieee.org/document/10095801)] [[arXiv](https://arxiv.org/abs/2210.15196)] [[code](https://github.com/yzyouzhang/hrtf_field)] [[video](https://youtu.be/HoQg8YzX1jg)] [[illuminate](https://illuminate.google.com/library?play=K7DSgh_8HMlW)] (**Recognized as one of the [top 3% of all papers accepted at ICASSP 2023](https://drive.google.com/file/d/1qTDdwqGuenJsZZoyFD2uBh_t6QUt0PPE/view?usp=sharing)**)

[1] You Zhang, Fei Jiang, and Zhiyao Duan, 
**One-Class Learning Towards Synthetic Voice Spoofing Detection**, 
*IEEE Signal Processing Letters*, 
vol. 28, pp. 937-941, 2021.
[[DOI](https://ieeexplore.ieee.org/document/9417604)] [[arXiv](https://arxiv.org/abs/2010.13995)] [[code](https://github.com/yzyouzhang/AIR-ASVspoof)] 
[[video](https://www.youtube.com/watch?v=pX9aq8CaIvk)] [[poster](https://labsites.rochester.edu/air/publications/ICASSP2022Poster_Neil.pdf)] [[slides](https://labsites.rochester.edu/air/publications/ICASSP2022Slides_Neil.pdf)] [[project](https://labsites.rochester.edu/air/projects/asvspoof.html)] [[illuminate](https://illuminate.google.com/library?play=RMGW3d__a5PH3)]


<!-- [3] Sefik Emre Eskimez, You Zhang, and Zhiyao Duan, **Speech Driven Talking Face Generation From a Single Image and an Emotion Condition**, *IEEE Transactions on Multimedia*, vol. 24, pp. 3480-3490, 2022. 
[[DOI](https://ieeexplore.ieee.org/document/9496264)] [[arXiv](https://arxiv.org/abs/2008.03592)] [[code](https://github.com/eeskimez/emotalkingface)] [[project](https://labsites.rochester.edu/air/projects/tfaceemo.html)] -->



<!-- # COMMENT EXPLAINING THIS PAGE -- 
[2] You Zhang, Ge Zhu, Fei Jiang, and Zhiyao Duan, <strong>An Empirical Study on Channel Effects for Synthetic Voice Spoofing Countermeasure Systems</strong>, in <em>Proc. Interspeech 2021</em>, pp. 4309-4313, 2021. &lt;<a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/zhang21ea_interspeech.pdf">pdf</a>&gt; &lt;<a href="https://www.isca-speech.org/archive/interspeech_2021/zhang21ea_interspeech.html">link</a>&gt; &lt;<a href="https://github.com/yzyouzhang/Empirical-Channel-CM">code</a>&gt; &lt;<a href="https://www.youtube.com/watch?v=t6qtehKer6w">video</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/publications/Zhang21channel_slides.pdf">slides</a>&gt; </p>
-->

<a href="https://info.flagcounter.com/w1Wy"><img src="https://s11.flagcounter.com/count2/w1Wy/bg_FFFFFF/txt_000000/border_CCCCCC/columns_8/maxflags_56/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>


  
