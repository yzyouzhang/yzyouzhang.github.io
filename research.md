---
layout: post-index
title: Publications
---

For the most up-to-date list of publications and citation counts, please visit my [Google Scholar profile](https://scholar.google.com/citations?hl=en&user=nYtHcRAAAAAJ&view_op=list_works&sortby=pubdate).

### Preprints

<p>[2] Kun Zhou, <strong>You Zhang</strong>, Shengkui Zhao, Hao Wang, Zexu Pan, Dianwen Ng, Chong Zhang, Chongjia Ni, Yukun Ma, Trung Hieu Nguyen, Jia Qi Yip, and Bin Ma,  <strong>Emotional Dimension Control in Language Model-Based Text-to-Speech: Spanning a Broad Spectrum of Human Emotions</strong>, 2025. &lt;<a href="https://arxiv.org/abs/2409.16681">arXiv</a>&gt; &lt;<a href="https://kunzhou9646.github.io/emo-icassp25/">demo</a>&gt;</p>

<p>[1] Yuxiang Wang, <strong>You Zhang</strong>, Zhiyao Duan, and Mark Bocko,  <strong>Predicting Global Head-Related Transfer Functions From Scanned Head Geometry Using Deep Learning and Compact Representations</strong>, 2025. &lt;<a href="https://arxiv.org/abs/2207.14352">arXiv</a>&gt; &lt;<a href="https://github.com/YuriWayne42/hrtf_personalization_fromMesh">code</a>&gt;</p>

<!-- <p>[1] <strong>You Zhang*</strong>, Ge Zhu*, Julia M. Soto*, Samantha E. Lettenberger*, Maryam Zafar, Peggy Auinger, Abigail Arky, Emma Waddell, Kelsey Spear, Rajbir Toor, Grace Nkrumah, Emily A. Hartman, Jacob Epifano, Michael J. Hasselberg, Anton P. Porsteinsson, Rich Christie, Zhiyao Duan, Aaron J. Masino, and E. Ray Dorsey,  <strong>Words Spoken Daily among Individuals with Neurodegenerative Conditions: A Pilot Study</strong>, 2023. (* equal contribution) </p> -->

### Book Chapters

<p>[1] <strong>You Zhang</strong>, Fei Jiang, Ge Zhu, Xinhui Chen, and Zhiyao Duan, <strong>Generalizing Voice Presentation Attack Detection to Unseen Synthetic Attacks and Channel Variation</strong>, Marcel, S., Fierrez, J., Evans, N. (eds) Handbook of Biometric Anti-Spoofing. Advances in Computer Vision and Pattern Recognition. Springer, Singapore, 2023. &lt;<a href="https://link.springer.com/chapter/10.1007/978-981-19-5288-3_15">link</a>&gt; &lt;<a href="https://github.com/yzyouzhang/HBAS_chapter_voice3">code</a>&gt; </p>

### Journals

<p>[3] Xin Wang, Héctor Delgado, Hemlata Tak, Jee-weon Jung, Hye-jin Shim, Massimiliano Todisco, Ivan Kukanov, Xuechen Liu, Md Sahidullah, Tomi Kinnunen, Nicholas Evans, Kong Aik Lee, Junichi Yamagishi, Myeonghun Jeong, Ge Zhu, Yongyi Zang, <strong>You Zhang</strong>, Soumi Maiti, Florian Lux, Nicolas Müller, Wangyou Zhang, Chengzhe Sun, Shuwei Hou, Siwei Lyu, Sébastien Le Maguer, Cheng Gong, Hanjie Guo, Liping Chen, and Vishwanath Singh. <strong>ASVspoof 5: Design, Collection, and Validation of Resources for Spoofing, Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech</strong>, in <em>Computer Speech & Language</em>, 2025. <a href="https://doi.org/10.1016/j.csl.2025.101825">DOI</a> <a href="https://doi.org/10.5281/zenodo.14498690">dataset</a></p>

<p>[2] Sefik Emre Eskimez, <strong>You Zhang</strong>, and Zhiyao Duan, <strong>Speech Driven Talking Face Generation From a Single Image and an Emotion Condition</strong>, <em>IEEE Transactions on Multimedia</em>, vol. 24, pp. 3480-3490, 2022. &lt;<a href="https://ieeexplore.ieee.org/document/9496264">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2008.03592">arXiv</a>&gt; &lt;<a href="https://github.com/eeskimez/emotalkingface">code</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/projects/tfaceemo.html">project</a>&gt; </p>

<p>[1] <strong>You Zhang</strong>, Fei Jiang, and Zhiyao Duan, <strong>One-Class Learning Towards Synthetic Voice Spoofing Detection</strong>, <em>IEEE Signal Processing Letters</em>, vol. 28, pp. 937-941, 2021. &lt;<a href="https://ieeexplore.ieee.org/document/9417604">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2010.13995">arXiv</a>&gt; &lt;<a href="https://github.com/yzyouzhang/AIR-ASVspoof">code</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/publications/ICASSP2022Poster_Neil.pdf">poster</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/publications/ICASSP2022Slides_Neil.pdf">slides</a>&gt; &lt;<a href="https://www.youtube.com/watch?v=pX9aq8CaIvk">video</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/projects/asvspoof.html">project</a>&gt; </p>

### Peer-reviewed Conferences and Workshops

<p>[19] <strong>You Zhang</strong>, Andrew Francl, Ruohan Gao, Paul Calamia, Zhiyao Duan, and Ishwarya Ananthabhotla. <strong>Towards Perception-Informed Latent HRTF Representations</strong>, in <em>Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em>, 2025. <a href="https://arxiv.org/abs/2507.02815">arXiv</a></p> 

<p>[18] <strong>You Zhang*</strong>, Baotong Tian*, Lin Zhang, and Zhiyao Duan. <strong>PartialEdit: Identifying Partial Deepfakes in the Era of Neural Speech Editing</strong>, in <em>Proc. Interspeech</em>, 2025. (* equal contribution) <a href="https://arxiv.org/abs/2506.02958">arXiv</a> <a href="https://doi.org/10.5281/zenodo.15519187">dataset</a> <a href="https://yzyouzhang.com/PartialEdit/">demo page</a></p> 

<p>[17] Kyungbok Lee$^\ddag$, <strong>You Zhang</strong>, and Zhiyao Duan. <strong>Audio Visual Segmentation Through Text Embeddings</strong>, in <em>Proc. IEEE International Conference on Image Processing (ICIP)</em>, 2025. <a href="https://arxiv.org/abs/2502.16359">arXiv</a> <a href="https://github.com/bok-bok/AV2T-SAM">code</a></p> 

<p>[16] Jiatong Shi, Hyejin Shim, Jinchuan Tian, Siddhant Arora, Haibin Wu, Darius Petermann, Jia Qi Yip, <strong>You Zhang</strong>, Yuxun Tang, Wangyou Zhang, Dareen Alharthi, Yichen Huang, Koichi Saito, Jionghao Han, Yiwen Zhao, Chris Donahue, and Shinji Watanabe. <strong>VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music</strong>, in <em><a href="https://openreview.net/group?id=aclweb.org/NAACL/2025/Demo_Track">Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) -- System Demonstration Track</a></em>, 2025. <a href="https://arxiv.org/abs/2412.17667">arXiv</a> <a href="https://github.com/shinjiwlab/versa">code</a></p>

<p>[15] <strong>You Zhang</strong>, Yongyi Zang, Jiatong Shi, Ryuichi Yamamoto, Tomoki Toda, and Zhiyao Duan, <strong>SVDD 2024: The Inaugural Singing Voice Deepfake Detection Challenge</strong>, in <em>Proc. IEEE Spoken Language Technology Workshop (SLT)</em>, 2024. &lt;<a href="https://ieeexplore.ieee.org/document/10832284">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2408.16132">arXiv</a>&gt; &lt;<a href="https://github.com/SVDDChallenge/CtrSVDD2024_Baseline">code</a>&gt; &lt;<a href="https://svddchallenge.org/">webpage</a>&gt;</p>

<p>[14] Kyungbok Lee, <strong>You Zhang</strong>, and Zhiyao Duan, <strong>A Multi-Stream Fusion Approach with One-Class Learning for Audio-Visual Deepfake Detection</strong>, in <em>Proc. IEEE 26th International Workshop on Multimedia Signal Processing (MMSP)</em>, 2024. &lt;<a href="https://ieeexplore.ieee.org/document/10743671">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2406.14176">arXiv</a>&gt; &lt;<a href="https://github.com/bok-bok/MSOC">code</a>&gt;</p>

<p>[13] Yongyi Zang, Jiatong Shi, <strong>You Zhang</strong>, Ryuichi Yamamoto, Jionghao Han, Yuxun Tang, Shengyuan Xu, Wenxiao Zhao, Jing Guo, Tomoki Toda, and Zhiyao Duan. <strong>CtrSVDD: A Benchmark Dataset and Baseline Analysis for Controlled Singing Voice Deepfake Detection</strong>, in <em>Proc. Interspeech</em>, 2024. &lt;<a href="https://www.isca-archive.org/interspeech_2024/zang24_interspeech.html">link</a>&gt; &lt;<a href="https://arxiv.org/pdf/2406.02438">arXiv</a>&gt; &lt;<a href="https://zenodo.org/records/10467648">dataset</a>&gt; </p>

<p>[12] Yongyi Zang*, <strong>You Zhang*</strong>, Mojtaba Heydari, and Zhiyao Duan,  <strong>SingFake: Singing Voice Deepfake Detection</strong>, in <em>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2024. (* equal contribution) &lt;<a href="https://ieeexplore.ieee.org/document/10448184">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2309.07525">arXiv</a>&gt; &lt;<a href="https://github.com/yongyizang/SingFake">code</a>&gt; &lt;<a href="https://www.singfake.org/">webpage</a>&gt;</p>

<p>[11] Enting Zhou, <strong>You Zhang</strong>, and Zhiyao Duan,  <strong>Learning Arousal-Valence Representation from Categorical Emotion Labels of Speech</strong>, in <em>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2024. &lt;<a href="https://ieeexplore.ieee.org/document/10445890">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2311.14816">arXiv</a>&gt; &lt;<a href="https://github.com/ETZET/SpeechEmotionAVLearning">code</a>&gt; </p>

<p>[10] Yutong Wen, <strong>You Zhang</strong>, and Zhiyao Duan, <strong>Mitigating Cross-Database Differences for Learning Unified HRTF Representation</strong>, in <em>Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em>, 2023. &lt;<a href="https://ieeexplore.ieee.org/document/10248178">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2307.14547">arXiv</a>&gt; &lt;<a href="https://github.com/YutongWen/HRTF_field_norm">code</a>&gt; &lt;<a href="https://youtu.be/NLxLF9mIc3U">video</a>&gt;</p>

<p>[9] Yongyi Zang, <strong>You Zhang</strong>, and Zhiyao Duan, <strong>Phase perturbation improves channel robustness for speech spoofing countermeasures</strong>, in <em>Proc. Interspeech</em>, 2023, pp. 3162-3166. &lt;<a href="https://www.isca-speech.org/archive/interspeech_2023/zang23_interspeech.html">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2306.03389">arXiv</a>&gt; &lt;<a href="https://github.com/yongyizang/PhaseAntispoofing_INTERSPEECH">code</a>&gt;</p>

<p>[8] <strong>You Zhang</strong>, Yuxiang Wang, and Zhiyao Duan, <strong>HRTF Field: Unifying Measured HRTF Magnitude Representation with Neural Fields</strong>, in <em>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2023. (<strong>Recognized as one of the <a href="https://drive.google.com/file/d/1qTDdwqGuenJsZZoyFD2uBh_t6QUt0PPE/view?usp=sharing">top 3% of all papers accepted at ICASSP 2023</a> </strong>) &lt;<a href="https://ieeexplore.ieee.org/document/10095801">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2210.15196">arXiv</a>&gt; &lt;<a href="https://github.com/yzyouzhang/hrtf_field">code</a>&gt; &lt;<a href="https://youtu.be/HoQg8YzX1jg">video</a>&gt; </p>

<p>[7] Siwen Ding, <strong>You Zhang</strong>, and Zhiyao Duan, <strong>SAMO: Speaker Attractor Multi-Center One-Class Learning for Voice Anti-Spoofing</strong>, in <em>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2023. &lt;<a href="https://ieeexplore.ieee.org/document/10094704">link</a>&gt; &lt;<a href="https://arxiv.org/abs/2211.02718">arXiv</a>&gt; &lt;<a href="https://github.com/sivannavis/samo">code</a>&gt; &lt;<a href="https://youtu.be/2szWD06keUg">video</a>&gt; </p>

<p>[6] Abudukelimu Wuerkaixi, Kunda Yan, <strong>You Zhang</strong>, Zhiyao Duan, and Changshui Zhang, <strong>DyViSE: Dynamic Vision-Guided Speaker Embedding for Audio-Visual Speaker Diarization</strong>, in <em>Proc. IEEE 24th International Workshop on Multimedia Signal Processing (MMSP)</em>, 2022, pp. 1-6. &lt;<a href="https://ieeexplore.ieee.org/document/9948860">link</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/publications/Wuerkaixi_DyViSE.pdf">pdf</a>&gt; &lt;<a href="https://github.com/zaocan666/DyViSE">code</a>&gt; </p>

<p>[5] Abudukelimu Wuerkaixi, <strong>You Zhang</strong>, Zhiyao Duan, and Changshui Zhang, <strong>Rethinking Audio-Visual Synchronization for Active Speaker Detection</strong>, in <em>Proc. IEEE 32nd International Workshop on Machine Learning for Signal Processing (MLSP)</em>, 2022, pp. 01-06. &lt;<a href="https://ieeexplore.ieee.org/document/9943352">link</a>&gt; &lt;<a href="https://arxiv.org/pdf/2206.10421.pdf">pdf</a>&gt; &lt;<a href="https://github.com/zaocan666/SyncTalkNet">code</a>&gt; </p>

<p>[4] <strong>You Zhang</strong>, Ge Zhu, and Zhiyao Duan, <strong>A Probabilistic Fusion Framework for Spoofing Aware Speaker Verification</strong>, in <em>Proc. The Speaker and Language Recognition Workshop (Odyssey)</em>, 2022, pp. 77-84. &lt;<a href="https://www.isca-speech.org/archive/odyssey_2022/zhang22b_odyssey.html">link</a>&gt; &lt;<a href="https://www.isca-speech.org/archive/pdfs/odyssey_2022/zhang22b_odyssey.pdf">pdf</a>&gt; &lt;<a href="https://github.com/yzyouzhang/SASV_PR">code</a>&gt; &lt;<a href="https://www.youtube.com/watch?v=98p-KLH3cKc">video</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/publications/Zhang22Odyssey.pdf">slides</a>&gt;</p>

<p>[3] Xinhui Chen*, <strong>You Zhang*</strong>, Ge Zhu*, and Zhiyao Duan, <strong>UR Channel-Robust Synthetic Speech Detection System for ASVspoof 2021</strong>, in <em>Proc. 2021 Edition of the Automatic Speaker Verification and Spoofing Countermeasures Challenge Workshop (ASVspoof)</em>, 2021, pp. 75-82. (* equal contribution) &lt;<a href="https://www.isca-speech.org/archive/asvspoof_2021/chen21_asvspoof.html">link</a>&gt; &lt;<a href="https://www.isca-speech.org/archive/pdfs/asvspoof_2021/chen21_asvspoof.pdf">pdf</a>&gt; &lt;<a href="https://github.com/yzyouzhang/ASVspoof2021_AIR">code</a>&gt; &lt;<a href="https://www.youtube.com/watch?v=-wKMOTp8Tt0">video</a>&gt; </p>

<p>[2] Yuxiang Wang, <strong>You Zhang</strong>, Zhiyao Duan, and Mark Bocko, <strong>Global HRTF Personalization Using Anthropometric Measures</strong>, in <em>Audio Engineering Society 150th Convention</em>, 2021. &lt;<a href="https://www.aes.org/e-lib/browse.cfm?elib=21095">link</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/publications/Wang21HRTF.pdf">pdf</a>&gt; &lt;<a href="https://github.com/YuriWayne42/hrtf_sht_personalization">code</a>&gt; </p>

<p>[1] <strong>You Zhang</strong>, Ge Zhu, Fei Jiang, and Zhiyao Duan, <strong>An Empirical Study on Channel Effects for Synthetic Voice Spoofing Countermeasure Systems</strong>, in <em>Proc. Interspeech</em>, 2021, pp. 4309-4313. &lt;<a href="https://www.isca-speech.org/archive/interspeech_2021/zhang21ea_interspeech.html">link</a>&gt; &lt;<a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/zhang21ea_interspeech.pdf">pdf</a>&gt; &lt;<a href="https://github.com/yzyouzhang/Empirical-Channel-CM">code</a>&gt; &lt;<a href="https://www.youtube.com/watch?v=t6qtehKer6w">video</a>&gt; &lt;<a href="https://labsites.rochester.edu/air/publications/Zhang21channel_slides.pdf">slides</a>&gt; &lt;<a href="https://zenodo.org/records/5794671">dataset</a>&gt; </p>

### Conference Abstracts
<p>[3] <strong>You Zhang</strong>, Yuxiang Wang, Mark Bocko, and Zhiyao Duan, <strong>Grid-agnostic personalized head-related transfer function modeling with neural fields</strong>, in <em>Acoustical Society of America 184th Meeting</em>, 2023. (<strong>Recognized by Signal Processing at the ASA Student Paper Award - Second Place</strong>)
            &lt;<a href="http://dx.doi.org/10.1121/10.0018387">link</a>&gt; </p>
            
<p>[2] Samantha E. Lettenberger, Maryam Zafar, Julia M. Soto, <strong>You Zhang</strong>, Ge Zhu, Aaron J. Masino, Grace Nkrumah, Emma Waddell, Kelsey Spear, Abigail Arky, Rajbir Toor, Emily Hartman, Jacob Epifano, Rich Christie, Zhiyao Duan, and Ray Dorsey, <strong>Words Spoken Daily: A Novel Measure of Cognition</strong>, in <em>International Congress of Parkinson’s Disease and Movement Disorders (MDS)</em>, 2023. 
            &lt;<a href="https://www.mdsabstracts.org/abstract/words-spoken-daily-a-novel-measure-of-cognition/">link</a>&gt; </p>
            
<p>[1] Yuxiang Wang, <strong>You Zhang</strong>, Zhiyao Duan, and Mark Bocko, <strong>Employing deep learning method to predict global head-related transfer functions from scanned head geometry</strong>, in <em>Acoustical Society of America 181th Meeting</em>, 2021. 
            &lt;<a href="https://doi.org/10.1121/10.0008543">link</a>&gt; </p>



<!-- # COMMENT EXPLAINING THIS PAGE -- 
https://labsites.rochester.edu/air/
We're currently using this section of the site to host these tutorials,
  but you might want to use it to showcase and describe your `Research`,
  to chronicle various `Talks` you've given over your history, or to
  write about various news or updates that have happened to you.

You can update the `title` of file (line 3) to change the heading of 
  the page and its title in the browser. To change how it's referred to
  in the navigation and/or adjust its url, see `data/navigation.yml` file.
-->
